{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78d73441-b596-4a24-852f-4f9590ed2e40",
   "metadata": {},
   "source": [
    "________________________________________________________________________________________________________________________\n",
    "# Experiment In comparing the predictions of an LSTM model with a RNN with attention layer for predicting temperature sequences\n",
    "## - Import Dependencies\n",
    "## - Define Dataset Class\n",
    "## - Define LSTM Class\n",
    "## - Define RNN with Attention Class\n",
    "## - Train and make predictions for both models in a main function\n",
    "## - Save each model's predicitons and actuals to CSV files for use in analysis using Tableau\n",
    "________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e456d5a9-7d1c-44f6-986f-209ee13b2e19",
   "metadata": {},
   "source": [
    "________________________________________________________________________________________________________________________\n",
    "### References:\n",
    "________________________________________________________________________________________________________________________\n",
    "- #### Video: LSTM Time Series Forecasting Tutorial in Python\n",
    "- #### Author: Greg Hogg\n",
    "- #### Link: https://www.youtube.com/watch?v=c0k-YLQGKjY\n",
    "________________________________________________________________________________________________________________________\n",
    "- #### Video: Neural Transformer Encoders for Timeseries Data in Keras (10.5)\n",
    "- #### Author: Jeff Heaton\n",
    "- #### Link: https://www.youtube.com/watch?v=SX67Mni0Or4\n",
    "\n",
    "\n",
    "________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3463b4eb-27ef-4c4a-a11b-6c959a80f087",
   "metadata": {},
   "source": [
    "________________________________________________________________________________________________________________________\n",
    "#### Dependencies\n",
    "________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76048b41-4966-45db-ae5a-2fd3867cf2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf  # NN Library\n",
    "\n",
    "import os  # For working with dataset\n",
    "import pandas as pd  # Data management\n",
    "import numpy as np  # Lin Alg\n",
    "\n",
    "from keras.models import Sequential  # Model initialization and format\n",
    "from keras.layers import *  # For setting up architecture\n",
    "from keras.callbacks import ModelCheckpoint  # For saving model that does best on val set\n",
    "from keras.losses import MeanSquaredError  # MSE works well for our loss function given the problem\n",
    "from keras.metrics import RootMeanSquaredError  # For extra evaluation\n",
    "from keras.optimizers import Adam  # Optimizer\n",
    "from keras.models import load_model  # To load saved models\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f335624-6f5e-4bc5-b907-fa94f2339cb4",
   "metadata": {},
   "source": [
    "________________________________________________________________________________________________________________________\n",
    "#### Dataset Class\n",
    "________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30de80e9-997c-4efb-88c5-c6b0f4c6ffe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Dataset class\n",
    "class Dataset():\n",
    "    # Define attributes for the model\n",
    "    def __init__(self, window_size=5):\n",
    "        # Window size for the input sequence\n",
    "        self.window_size = window_size\n",
    "\n",
    "        # Load data and keep only the temperature column\n",
    "        self.df = self.load_data()\n",
    "        self.df = self.df[\"T (degC)\"]\n",
    "\n",
    "        # Convert DataFrame to numpy array\n",
    "        self.df_as_np = self.df.to_numpy()\n",
    "\n",
    "        # Transform data to format that works for supervised learning\n",
    "        self.X, self.y = self.to_X_y()\n",
    "\n",
    "        # Split data into training, validation and testing datasets\n",
    "        self.X_train, self.y_train, self.X_val, self.y_val, self.X_test, self.y_test = self.train_test_split()\n",
    "        \n",
    "    def load_data(self):\n",
    "        # Download and extract dataset\n",
    "        zip_path = tf.keras.utils.get_file(\n",
    "                        origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip',\n",
    "                        fname='jena_climate_2009_2016.csv.zip',\n",
    "                        extract=True)\n",
    "\n",
    "        # Locate the CSV file\n",
    "        csv_path, _ = os.path.splitext(zip_path)\n",
    "\n",
    "        # Load data into a DataFrame and set the index to datetime\n",
    "        df = pd.read_csv(csv_path)\n",
    "        df.index = pd.to_datetime(df['Date Time'], format='%d.%m.%Y %H:%M:%S')\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def to_X_y(self):\n",
    "        # Function to transform the sequence data into a format suitable for supervised learning\n",
    "        X, y = [], []\n",
    "        for i in range(len(self.df_as_np) - self.window_size):\n",
    "            # Create sequences of the given window size\n",
    "            row = [[a] for a in self.df_as_np[i:i + self.window_size]]\n",
    "\n",
    "            # Append the sequence and the corresponding label\n",
    "            X.append(row)\n",
    "            label = self.df_as_np[i + self.window_size]\n",
    "            y.append(label)\n",
    "        \n",
    "        # Transform data into numpy arrays\n",
    "        return np.array(X), np.array(y).astype('float32')\n",
    "    \n",
    "    def train_test_split(self):\n",
    "        # Split data into training, validation and testing datasets\n",
    "        # First 400,000 samples are used for training\n",
    "        X_train, y_train = self.X[:400000], self.y[:400000]\n",
    "\n",
    "        # Next 10,000 samples are used for validation\n",
    "        X_val, y_val = self.X[400000:410000], self.y[400000:410000]\n",
    "\n",
    "        # The remaining samples are used for testing\n",
    "        X_test, y_test = self.X[410000:], self.y[410000:]\n",
    "\n",
    "        return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e38bdbb-d243-4bce-96ac-a73580d7e181",
   "metadata": {},
   "source": [
    "________________________________________________________________________________________________________________________\n",
    "#### LSTM Class\n",
    "________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d75a549d-83d1-4e29-b55c-d16a28569481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining LSTM model for time series prediction\n",
    "class LSTM_for_timeseries():\n",
    "    def __init__(self):\n",
    "        # Initializing model with Sequential API, which stacks layers sequentially\n",
    "        self.model = Sequential()\n",
    "\n",
    "        # Input layer with input shape of 5 time steps with 1 feature\n",
    "        self.model.add(InputLayer((5,1)))\n",
    "        \n",
    "        # Adding LSTM layer with 64 units \n",
    "        self.model.add(LSTM(64))\n",
    "\n",
    "        # Dense layer with 8 units and a Rectified Linear Unit activation function\n",
    "        self.model.add(Dense(8, 'relu'))\n",
    "\n",
    "        # Output layer with single unit for regression task\n",
    "        self.model.add(Dense(1, 'linear'))\n",
    "        \n",
    "        # Defining a callback for model checkpointing, it saves the model that performs best on validation data\n",
    "        self.checkpoint = ModelCheckpoint('best_model_LSTM', save_best_only = True)\n",
    "\n",
    "        # Variables to store the best model, the predictions it makes, and the results\n",
    "        self.model_best = None\n",
    "        self.predictions = None\n",
    "        self.results = None\n",
    "\n",
    "    # Function to train the model\n",
    "    def train_model(self, X_train, y_train, X_val, y_val):\n",
    "        # Compiling model with Mean Squared Error as loss function, Adam optimizer and Root Mean Squared Error as a metric\n",
    "        self.model.compile(loss = MeanSquaredError(), optimizer = Adam(learning_rate = 0.01), metrics = [RootMeanSquaredError()])\n",
    "\n",
    "        # Training the model for 10 epochs, validation data is provided to compute validation loss and metrics at the end of each epoch\n",
    "        # Checkpoint callback is provided which will save the best model observed during training \n",
    "        self.model.fit(X_train, y_train, validation_data = (X_val, y_val), epochs = 10, callbacks = [self.checkpoint])\n",
    "\n",
    "    # Function to test the model\n",
    "    def test_model(self, X_test, y_test):\n",
    "        # Loading the best saved model\n",
    "        self.model_best = load_model('best_model_LSTM')\n",
    "\n",
    "        # Making predictions using the best model and flattening the predictions array\n",
    "        self.predictions = self.model_best.predict(X_test).flatten()\n",
    "\n",
    "        # Creating a dataframe with predictions and actual values\n",
    "        self.results = pd.DataFrame(data = {\"Predictions\": self.predictions, 'Actuals': y_test})\n",
    "\n",
    "    # Function to save the predictions and actual values to a csv file\n",
    "    def save_results_to_csv(self):\n",
    "        self.results.to_csv(\"Predictions_and_Actuals_for_test_set_LSTM_best_model.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc7e984-0bab-410a-b7c5-f1c3162cccc8",
   "metadata": {},
   "source": [
    "________________________________________________________________________________________________________________________\n",
    "#### RNN with Attention Mechanism Class\n",
    "________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d4978f4-63f5-44e8-89d1-7bde88fe8cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a recurrent neural network (RNN) with attention mechanism for time series prediction\n",
    "class RNN_with_Attention_for_timeseries():\n",
    "    def __init__(self):\n",
    "        # Build and initialize the model with predefined parameters\n",
    "        self.model = self.build_model(\n",
    "                    (5,1),                      # Input shape: 5 time steps with 1 feature\n",
    "                    head_size=256,              # The dimensionality of the output space of the attention heads\n",
    "                    num_heads=4,                # Number of attention heads\n",
    "                    ff_dim=4,                   # Dimensionality of the output space of the feed-forward network\n",
    "                    num_transformer_blocks=4,   # Number of transformer blocks\n",
    "                    mlp_units=[128],            # Units in the dense layer\n",
    "                    mlp_dropout=0.4,            # Dropout rate for the dense layer\n",
    "                    dropout=0.25                # Dropout rate for attention and feed-forward network\n",
    "                    )\n",
    "                    \n",
    "        # Defining a callback for model checkpointing, it saves the model that performs best on validation data\n",
    "        self.checkpoint = ModelCheckpoint('best_model_RNN_with_Attention', save_best_only = True)\n",
    "\n",
    "        # Variables to store the best model, the predictions it makes, and the results\n",
    "        self.model_best = None\n",
    "        self.predictions = None\n",
    "        self.results = None\n",
    "        \n",
    "    # Function to implement transformer encoder\n",
    "    def transformer_encoder(self, inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "        # Layer Normalization and Multihead Attention\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "        x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "        res = x + inputs\n",
    "\n",
    "        # Feed-Forward network\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "        x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "        x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "        return x + res                    \n",
    "\n",
    "    # Function to build the model\n",
    "    def build_model(self, input_shape,\n",
    "                    head_size,\n",
    "                    num_heads,\n",
    "                    ff_dim,\n",
    "                    num_transformer_blocks,\n",
    "                    mlp_units,\n",
    "                    dropout=0,\n",
    "                    mlp_dropout=0):\n",
    "        inputs = layers.Input(shape=input_shape)\n",
    "        x = inputs\n",
    "        # Add the specified number of transformer blocks\n",
    "        for _ in range(num_transformer_blocks):\n",
    "            x = self.transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "        # Apply Global Average Pooling\n",
    "        x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "        \n",
    "        # Dense layers\n",
    "        for dim in mlp_units:\n",
    "            x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "            x = layers.Dropout(mlp_dropout)(x)\n",
    "        \n",
    "        # Output layer\n",
    "        outputs = layers.Dense(1)(x)\n",
    "                            \n",
    "        return keras.Model(inputs, outputs)\n",
    "                            \n",
    "    # Function to train the model\n",
    "    def train_model(self, X_train, y_train, X_val, y_val):\n",
    "        # Compiling model with Mean Squared Error as loss function, Adam optimizer and Root Mean Squared Error as a metric\n",
    "        self.model.compile(loss = MeanSquaredError(), optimizer = Adam(learning_rate = 0.01), metrics = [RootMeanSquaredError()])\n",
    "\n",
    "        # Training the model for 10 epochs, validation data is provided to compute validation loss and metrics at the end of each epoch\n",
    "        # Checkpoint callback is provided which will save the best model observed during training \n",
    "        self.model.fit(X_train, y_train, validation_data = (X_val, y_val), epochs = 10, callbacks = [self.checkpoint])\n",
    "    \n",
    "    # Function to test the model\n",
    "    def test_model(self, X_test, y_test):\n",
    "        # Loading the best saved model\n",
    "        self.model_best = load_model('best_model_RNN_with_Attention')\n",
    "\n",
    "        # Making predictions using the best model and flattening the predictions array\n",
    "        self.predictions = self.model_best.predict(X_test).flatten()\n",
    "\n",
    "        # Creating a dataframe with predictions and actual values\n",
    "        self.results = pd.DataFrame(data = {\"Predictions\": self.predictions, 'Actuals': y_test})\n",
    "\n",
    "    # Function to save the predictions and actual values to a csv file\n",
    "    def save_results_to_csv(self):\n",
    "        self.results.to_csv(\"Predictions_and_Actuals_for_test_set_RNN_with_Attention_best_model.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa97988-dfb3-49ff-8ae3-8841b4ee7322",
   "metadata": {},
   "source": [
    "________________________________________________________________________________________________________________________\n",
    "#### Class to Calculate RMSE score for either model\n",
    "________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cc78471-d841-42a9-a521-3caf1a19efea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class for calculating and displaying Root Mean Square Error (RMSE)\n",
    "class Calculate_RMSE():\n",
    "    def __init__(self):\n",
    "        # Initialize Mean Squared Error (MSE) loss function from TensorFlow\n",
    "        self.mse_loss = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "    # Method to calculate and display RMSE\n",
    "    def display_RMSE(self, y_test, test_predictions, modelname):\n",
    "        # Calculate MSE score\n",
    "        mse_score = self.mse_loss(y_test, test_predictions)\n",
    "        # Calculate RMSE by taking square root of MSE\n",
    "        rmse_score = tf.sqrt(mse_score)\n",
    "        # Print RMSE score\n",
    "        print(f\"Best {modelname}'s RMSE on test dataset: {rmse_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdbd7f0-9c25-4556-bf84-b76b5583729d",
   "metadata": {},
   "source": [
    "________________________________________________________________________________________________________________________\n",
    "#### Set up dataset, train models, use best model to make predictions, save predictions and actuals for apples-to-apples model comparison for predicting temperature sequences in a time-series dataset used for monitoring climate change\n",
    "________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "570c2a7e-5aaa-4ecb-9c1b-ffdea4f5d54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Create an instance of Dataset\n",
    "    data = Dataset()\n",
    "    \n",
    "    # Transform the sequence data into a format suitable for supervised learning\n",
    "    data.to_X_y()\n",
    "    \n",
    "    # Split the data into training, validation, and testing datasets\n",
    "    data.train_test_split()\n",
    "    \n",
    "    # Create an instance of the LSTM_for_timeseries model\n",
    "    LSTM_model = LSTM_for_timeseries()\n",
    "    \n",
    "    # Train the LSTM model\n",
    "    LSTM_model.train_model(data.X_train, data.y_train, data.X_val, data.y_val)\n",
    "    \n",
    "    # Test the LSTM model on the testing dataset\n",
    "    LSTM_model.test_model(data.X_test, data.y_test)\n",
    "    \n",
    "    # Save the results to a CSV file\n",
    "    LSTM_model.save_results_to_csv()\n",
    "    \n",
    "    # Calculate RMSE for LSTM model\n",
    "    LSTM_RMSE_scores = Calculate_RMSE()\n",
    "    LSTM_RMSE_scores.display_RMSE(data.y_test, LSTM_model.predictions, \"LSTM model\")\n",
    "    \n",
    "    # Create an instance of the RNN_with_Attention_for_timeseries model\n",
    "    RNN_with_Attention_model = RNN_with_Attention_for_timeseries()\n",
    "    \n",
    "    # Train the RNN_with_Attention model\n",
    "    RNN_with_Attention_model.train_model(data.X_train, data.y_train, data.X_val, data.y_val)\n",
    "    \n",
    "    # Test the RNN_with_Attention model on the testing dataset\n",
    "    RNN_with_Attention_model.test_model(data.X_test, data.y_test)\n",
    "    \n",
    "    # Save the results to a CSV file\n",
    "    RNN_with_Attention_model.save_results_to_csv()\n",
    "    \n",
    "    # Calculate RMSE for RNN_with_Attention model\n",
    "    RNN_with_Attention_model_RMSE_scores = Calculate_RMSE()\n",
    "    RNN_with_Attention_model_RMSE_scores.display_RMSE(data.y_test, RNN_with_Attention_model.predictions, \"RNN with Attention model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5198d3df-7189-4e9b-9c5d-37347e9747d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12490/12500 [============================>.] - ETA: 0s - loss: 0.1945 - root_mean_squared_error: 0.4410"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model_LSTM\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model_LSTM\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 30s 2ms/step - loss: 0.1944 - root_mean_squared_error: 0.4409 - val_loss: 0.0553 - val_root_mean_squared_error: 0.2351\n",
      "Epoch 2/10\n",
      "12497/12500 [============================>.] - ETA: 0s - loss: 0.0590 - root_mean_squared_error: 0.2429"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model_LSTM\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model_LSTM\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 27s 2ms/step - loss: 0.0590 - root_mean_squared_error: 0.2429 - val_loss: 0.0499 - val_root_mean_squared_error: 0.2235\n",
      "Epoch 3/10\n",
      "12477/12500 [============================>.] - ETA: 0s - loss: 0.0561 - root_mean_squared_error: 0.2368"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model_LSTM\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model_LSTM\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 27s 2ms/step - loss: 0.0561 - root_mean_squared_error: 0.2368 - val_loss: 0.0491 - val_root_mean_squared_error: 0.2217\n",
      "Epoch 4/10\n",
      "12487/12500 [============================>.] - ETA: 0s - loss: 0.0540 - root_mean_squared_error: 0.2325"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model_LSTM\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model_LSTM\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 27s 2ms/step - loss: 0.0541 - root_mean_squared_error: 0.2325 - val_loss: 0.0476 - val_root_mean_squared_error: 0.2182\n",
      "Epoch 5/10\n",
      "12500/12500 [==============================] - 22s 2ms/step - loss: 0.0534 - root_mean_squared_error: 0.2310 - val_loss: 0.0502 - val_root_mean_squared_error: 0.2240\n",
      "Epoch 6/10\n",
      "12500/12500 [==============================] - 22s 2ms/step - loss: 0.0527 - root_mean_squared_error: 0.2296 - val_loss: 0.0612 - val_root_mean_squared_error: 0.2474\n",
      "Epoch 7/10\n",
      "12500/12500 [==============================] - 22s 2ms/step - loss: 0.0521 - root_mean_squared_error: 0.2283 - val_loss: 0.0484 - val_root_mean_squared_error: 0.2201\n",
      "Epoch 8/10\n",
      "12500/12500 [==============================] - 23s 2ms/step - loss: 0.0515 - root_mean_squared_error: 0.2270 - val_loss: 0.0552 - val_root_mean_squared_error: 0.2349\n",
      "Epoch 9/10\n",
      "12500/12500 [==============================] - 23s 2ms/step - loss: 0.0528 - root_mean_squared_error: 0.2298 - val_loss: 0.1199 - val_root_mean_squared_error: 0.3463\n",
      "Epoch 10/10\n",
      "12500/12500 [==============================] - 23s 2ms/step - loss: 0.0524 - root_mean_squared_error: 0.2288 - val_loss: 0.0486 - val_root_mean_squared_error: 0.2205\n",
      "330/330 [==============================] - 1s 988us/step\n",
      "Best LSTM model's RMSE on test dataset: 0.15906491875648499\n",
      "Epoch 1/10\n",
      "12496/12500 [============================>.] - ETA: 0s - loss: 1.8510 - root_mean_squared_error: 1.3605"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 56). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model_RNN_with_Attention\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model_RNN_with_Attention\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 137s 11ms/step - loss: 1.8509 - root_mean_squared_error: 1.3605 - val_loss: 0.4111 - val_root_mean_squared_error: 0.6412\n",
      "Epoch 2/10\n",
      "12497/12500 [============================>.] - ETA: 0s - loss: 1.6009 - root_mean_squared_error: 1.2653"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 56). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model_RNN_with_Attention\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model_RNN_with_Attention\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 132s 11ms/step - loss: 1.6007 - root_mean_squared_error: 1.2652 - val_loss: 0.1474 - val_root_mean_squared_error: 0.3839\n",
      "Epoch 3/10\n",
      "12498/12500 [============================>.] - ETA: 0s - loss: 1.6551 - root_mean_squared_error: 1.2865"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 56). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model_RNN_with_Attention\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model_RNN_with_Attention\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 139s 11ms/step - loss: 1.6551 - root_mean_squared_error: 1.2865 - val_loss: 0.0745 - val_root_mean_squared_error: 0.2729\n",
      "Epoch 4/10\n",
      "12497/12500 [============================>.] - ETA: 0s - loss: 1.6544 - root_mean_squared_error: 1.2863"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 56). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model_RNN_with_Attention\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model_RNN_with_Attention\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 200s 16ms/step - loss: 1.6546 - root_mean_squared_error: 1.2863 - val_loss: 0.0656 - val_root_mean_squared_error: 0.2561\n",
      "Epoch 5/10\n",
      "12499/12500 [============================>.] - ETA: 0s - loss: 1.6960 - root_mean_squared_error: 1.3023"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 56). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model_RNN_with_Attention\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model_RNN_with_Attention\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 166s 13ms/step - loss: 1.6959 - root_mean_squared_error: 1.3023 - val_loss: 0.0567 - val_root_mean_squared_error: 0.2381\n",
      "Epoch 6/10\n",
      "12500/12500 [==============================] - 153s 12ms/step - loss: 1.7568 - root_mean_squared_error: 1.3255 - val_loss: 0.6346 - val_root_mean_squared_error: 0.7966\n",
      "Epoch 7/10\n",
      "12500/12500 [==============================] - 158s 13ms/step - loss: 1.8048 - root_mean_squared_error: 1.3434 - val_loss: 0.1776 - val_root_mean_squared_error: 0.4215\n",
      "Epoch 8/10\n",
      "12500/12500 [==============================] - 149s 12ms/step - loss: 1.8331 - root_mean_squared_error: 1.3539 - val_loss: 1.6959 - val_root_mean_squared_error: 1.3023\n",
      "Epoch 9/10\n",
      "12500/12500 [==============================] - 151s 12ms/step - loss: 1.8514 - root_mean_squared_error: 1.3607 - val_loss: 0.2110 - val_root_mean_squared_error: 0.4594\n",
      "Epoch 10/10\n",
      "12500/12500 [==============================] - 154s 12ms/step - loss: 1.8824 - root_mean_squared_error: 1.3720 - val_loss: 0.1026 - val_root_mean_squared_error: 0.3203\n",
      "330/330 [==============================] - 2s 6ms/step\n",
      "Best RNN with Attention model's RMSE on test dataset: 0.19057580828666687\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
